# SP0501-MAJOR-PROJECT

Sign Language Translator (Major Project)
Project Overview

The Sign Language Translator is an advanced real-time computer vision and machine learning system that recognizes hand gestures through live video and translates them into readable text and audible speech.

This project captures live video input from a webcam, detects hand landmarks using MediaPipe, classifies gestures using a trained machine learning model, and converts recognized sign language gestures into:

Real-time Text Output
Audio (Speech) Output

The system enables seamless communication between sign language users and non-sign language users.

-----Key Features--------

Live Video Gesture Recognition
Custom Trained Machine Learning Model
Hand Landmark Detection using MediaPipe
Real-time Sign-to-Text Translation
Text-to-Speech Audio Output
Scikit-learn Based Classification Model

------Technologies Used-----

Python 3.10
OpenCV
MediaPipe
NumPy
Scikit-learn
Pickle
Text-to-Speech Library

